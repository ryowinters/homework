{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660becee-9793-4db8-9952-e4c024e4d31a",
   "metadata": {},
   "source": [
    "平时作业-求二元函数的偏导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cc23ad-12bf-4220-b670-167a1accb5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关于x的偏导数: tensor([-0.4328])\n",
      "关于y的偏导数: tensor([-1.7013])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义x和y张量，这里示例为随机初始化的值，并设置requires_grad=True\n",
    "x = torch.randn(1, requires_grad=True)\n",
    "y = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# 定义函数f(x,y)\n",
    "def f(x, y):\n",
    "    return x ** 2 + y ** 2\n",
    "\n",
    "# 计算函数值\n",
    "z = f(x, y)\n",
    "\n",
    "# 将z变成标量（这里通过求和操作）\n",
    "z_scalar = z.sum()\n",
    "\n",
    "# 计算z_scalar关于x的偏导数\n",
    "z_scalar.backward(retain_graph=True)\n",
    "print(\"关于x的偏导数:\", x.grad)\n",
    "\n",
    "# 清空之前计算的梯度，以便重新计算关于y的偏导数\n",
    "x.grad.zero_()\n",
    "y.grad.zero_()\n",
    "\n",
    "# 计算z_scalar关于y的偏导数\n",
    "z_scalar.backward()\n",
    "print(\"关于y的偏导数:\", y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34355b-ccb5-4f33-9f2d-a97ab07aec04",
   "metadata": {},
   "source": [
    "使用torch张量自行实现sigmoid激活函数，并计算在它在x=0点处的导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba648968-2088-4ece-8a22-a6c0d13e4d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid函数在x=0处的导数是： 0.25\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "\n",
    "x = torch.tensor(0.0, requires_grad=True)\n",
    "y = sigmoid(x)\n",
    "y.backward()\n",
    "derivative_at_0 = x.grad\n",
    "print(\"Sigmoid函数在x=0处的导数是：\", derivative_at_0.item ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c08f3b4-a528-47aa-995e-d2b116cd91fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(1.)\n",
      "x2对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(0.)\n",
      "x1对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(0.)\n",
      "x2对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(1.)\n",
      "x1对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(0.5000)\n",
      "x2对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(0.)\n",
      "x1对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(5.)\n",
      "x2对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(2.)\n",
      "x1对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(0.)\n",
      "x2对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(0.2837)\n",
      "x1对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(5.5000)\n",
      "x2对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(2.)\n",
      "x1对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(5.5000)\n",
      "x2对{'x1': tensor(2., requires_grad=True), 'x2': tensor(5., requires_grad=True)}的导数: tensor(1.7163)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def sin(x):\n",
    "    return torch.sin(x)\n",
    "\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(5.0, requires_grad=True)\n",
    "v_minus_1 = x1\n",
    "v0 = x2\n",
    "v1 = torch.log(v_minus_1)\n",
    "v2 = v_minus_1*v0\n",
    "v3 = sin(v0)\n",
    "v4 = v1+v2\n",
    "v5 = v4-v3\n",
    "\n",
    "if x1.grad is not None:\n",
    "    x1.grad.zero_()\n",
    "else:\n",
    "    x1.grad = torch.tensor(0.0)\n",
    "if x2.grad is not None:\n",
    "    x2.grad.zero_()\n",
    "else:\n",
    "    x2.grad = torch.tensor(0.0)\n",
    "\n",
    "v3.backward(retain_graph=True)\n",
    "\n",
    "node_dict = {\"v_minus_1\":v_minus_1,\"v0\":v0,\"v1\":v1,\"v2\":v2,\"v3\":v3,\"v4\":v4,\"v5\":v5}\n",
    "var_dict = {\"x1\":x1,\"x2\":x2}\n",
    "\n",
    "for node_name in node_dict:\n",
    "    for var_name in var_dict:\n",
    "        if x1.grad is not None:\n",
    "            x1.grad.zero_()\n",
    "        else:\n",
    "            x1.grad = torch.tensor(0.0)\n",
    "        if x2.grad is not None:\n",
    "            x2.grad.zero_()\n",
    "        else:\n",
    "            x2.grad = torch.tensor(0.0)\n",
    "\n",
    "        node_dict[node_name].backward(retain_graph=True)\n",
    "        print(f\"{var_name}对{var_dict}的导数:\",var_dict[var_name].grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd1c178-0b98-4629-8ff3-25bc4c640967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3对x2的导数: tensor(1.7163)\n",
      "v3对x1的导数: tensor(5.5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"v3对x2的导数:\",x2.grad)\n",
    "print(\"v3对x1的导数:\",x1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf66a22-8154-4447-bd0e-9d22af935fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7163)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad\n",
    "x2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60d6e8-f106-4296-9975-146fd0c77e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
